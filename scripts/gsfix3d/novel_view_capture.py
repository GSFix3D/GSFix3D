# SPDX-FileCopyrightText: 2025 Mobile Robotics Lab, Technical University of Munich
# SPDX-FileCopyrightText: 2025 Jiaxin Wei
# SPDX-License-Identifier: Apache-2.0


import os
import sys
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..', '..')))
import json
import argparse
import numpy as np
import open3d as o3d
from PIL import Image
from tqdm import tqdm
import torch

from gs.camera import Camera
from gs.gaussian_model import GaussianModel
from gs.gaussian_renderer import render
from gs.general_utils import searchForMaxIteration, focal2fov
from gs.arguments import ModelParams, PipelineParams, get_combined_args

from scripts.utils import read_replica_cameras, read_scannetpp_cameras, render_mesh


def save_camera_poses(vis):
    """Save the current camera pose when 'R' is pressed."""
    global poses
    ctr = vis.get_view_control()
    cam_params = ctr.convert_to_pinhole_camera_parameters()
    
    # Extract camera pose as a dictionary
    cam_pose = {
        "extrinsic": cam_params.extrinsic.tolist()
    }
    
    poses.append(cam_pose)
    
    # Save to file
    with open(POSES_FILE, "w") as f:
        json.dump(poses, f, indent=4)
    
    print(f"Camera pose saved! Total poses: {len(poses)}")
    return False  # Keep visualization running


def R_key_callback(vis):
    save_camera_poses(vis)


def Q_key_callback(vis):
    vis.close()


def main(args, model_params, pipeline_params):
    # Confirm which 3DGS model to use (following the file structure generated by the Inria 3DGS code)
    if args.iteration == -1:
        loaded_iter = searchForMaxIteration(os.path.join(model_params.model_path, "point_cloud"))
    else:
        loaded_iter = args.iteration

    # Capture novel view poses to be fixed (need to load mesh for visualization)
    if args.data_type == "replica":
        intrinsics = read_replica_cameras(args.data_path, intrinsics_only=True)
    elif args.data_type == "scannetpp":
        intrinsics = read_scannetpp_cameras(args.data_path, intrinsics_only=True)
    else:
        raise TypeError(f"Unsupported dataset type: {args.data_type}!")

    custom_intrinsic = o3d.camera.PinholeCameraIntrinsic(
        intrinsics["width"], intrinsics["height"], intrinsics["fx"], intrinsics["fy"], intrinsics["cx"], intrinsics["cy"]
    )

    mesh_file = os.path.join(model_params.model_path, "mesh", "mesh_" + str(loaded_iter) + ".ply")
    if not os.path.exists(mesh_file):
        raise FileNotFoundError(f"{mesh_file} doesn't exist!")
    mesh = o3d.io.read_triangle_mesh(mesh_file)

    vis = o3d.visualization.VisualizerWithKeyCallback()
    vis.create_window(width=intrinsics["width"], height=intrinsics["height"])
    vis.add_geometry(mesh)
    vis.register_key_callback(ord("R"), R_key_callback)
    vis.register_key_callback(ord("Q"), Q_key_callback)

    ctr = vis.get_view_control()
    cam_params = ctr.convert_to_pinhole_camera_parameters()
    cam_params.intrinsic = custom_intrinsic
    ctr.convert_from_pinhole_camera_parameters(cam_params, allow_arbitrary=True)

    print("Press 'R' to save camera pose, 'Q' to quit.")
    vis.run()
    vis.destroy_window()

    # Render gs and (optionally) mesh images from captured novel views
    print("Start rendering gs/mesh images from captured novel views...")
    if torch.cuda.is_available():
        device = torch.device("cuda:0")
        torch.cuda.set_device(device)
    else:
        raise Exception("No GPU is found!")

    gaussians = GaussianModel(model_params.sh_degree)
    gaussians.load_ply(os.path.join(model_params.model_path,
                                    "point_cloud",
                                    "iteration_" + str(loaded_iter),
                                    "point_cloud.ply"))

    fov_x = focal2fov(intrinsics["fx"], intrinsics["width"])
    fov_y = focal2fov(intrinsics["fy"], intrinsics["height"])
    bg_color = [1, 1, 1] if model_params.white_background else [0, 0, 0]
    background = torch.tensor(bg_color, dtype=torch.float32, device=device)

    for i in tqdm(range(len(poses))):
        T_CW = np.array(poses[i]["extrinsic"])
        T_WC = np.linalg.inv(T_CW)
        
        # Render mesh
        if render_mesh:
            rgb = render_mesh(mesh, intrinsics, T_WC[:3, :3], T_WC[:3, 3])
            rgb = rgb.astype(np.uint8)
            save_path = os.path.join(sub_dir, "mesh_image", f"{i:05d}.png")
            Image.fromarray(rgb).save(save_path, format="PNG")

        # Render gs
        gs_cam = Camera(R=T_CW[:3, :3], T=T_CW[:3, 3], FoVx=fov_x, FoVy=fov_y, width=intrinsics["width"], height=intrinsics["height"])
        with torch.no_grad():
            rendered_gs = render(gs_cam, gaussians, pipeline_params, background)["render"]
            rendered_gs_image = rendered_gs.detach().cpu().numpy().transpose(1, 2, 0) * 255
            rendered_gs_image = rendered_gs_image.astype(np.uint8)
            save_path = os.path.join(sub_dir, "gs_image", f"{i:05d}.png")
            Image.fromarray(rendered_gs_image).save(save_path, format="PNG")


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Novel View Capture for GSFix3D")

    model = ModelParams(parser, sentinel=True)
    pipeline = PipelineParams(parser)

    parser.add_argument("--iteration", type=int, default=-1, help="A 3DGS model from this specific iteration will be loaded following Inria 3DGS file structure")
    parser.add_argument("--data_type", type=str, default="replica", choices=["replica", "scannetpp"], help="Supported data type")
    parser.add_argument("--data_path", type=str, help="Path to your customized data")
    parser.add_argument("--render_mesh", action="store_true", help="Enable mesh image rendering")
    parser.add_argument("--output_dir", type=str, default="output_novel_views", help="Folder path to store results")
    args = get_combined_args(parser)

    os.makedirs(args.output_dir, exist_ok=True)
    sub_dir = os.path.join(args.output_dir, "rendered_novel_views")
    os.makedirs(os.path.join(sub_dir, "gs_image"), exist_ok=True)
    if render_mesh:
        os.makedirs(os.path.join(sub_dir, "mesh_image"), exist_ok=True)

    POSES_FILE = os.path.join(args.output_dir, "novel_views.json")
    poses = []  # List to store camera poses
    main(args, model.extract(args), pipeline.extract(args))
