# SPDX-FileCopyrightText: 2025 Mobile Robotics Lab, Technical University of Munich
# SPDX-FileCopyrightText: 2025 Jiaxin Wei
# SPDX-License-Identifier: Apache-2.0


import os
import sys
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..', '..')))
import json
import shutil
import torch
import random
import argparse
import numpy as np
from glob import glob
from tqdm import tqdm
from PIL import Image
from torchvision import transforms

from gs.camera import Camera
from gs.gaussian_model import GaussianModel
from gs.gaussian_renderer import render
from gs.general_utils import searchForMaxIteration, focal2fov
from gs.loss_utils import l1_loss, ssim
from gs.arguments import ModelParams, OptimizationParams, PipelineParams, get_combined_args

from scripts.utils import read_replica_cameras, read_scannetpp_cameras, eval_image


def main(args, model_params, optim_params, pipeline_params):
    if torch.cuda.is_available():
        device = torch.device("cuda:0")
        torch.cuda.set_device(device)
    else:
        raise Exception("No GPU is found!")

    os.makedirs(args.output_dir, exist_ok=True)
    os.makedirs(os.path.join(args.output_dir, "refined_novel_views"), exist_ok=True)

    # Load fixed novel view images obtained from GSFixer
    fixed_rgb_file_paths = sorted(glob(os.path.join(args.fixed_image_path, "*.png")))

    # Load ground truth data from supported data_type
    if args.data_type == "replica":
        train_rgb_file_paths = sorted(glob(os.path.join(args.data_path, "results", "frame*.jpg")))
        test_rgb_file_paths = sorted(glob(os.path.join(args.data_path, "novel_views", "frame*.jpg")))
        train_camera_poses, test_camera_poses, intrinsics = read_replica_cameras(args.data_path)
    elif args.data_type == "scannetpp":
        split_file = os.path.join(args.data_path, "train_test_lists.json")
        if not os.path.exists(split_file):
            raise FileNotFoundError(f"{split_file} doesn't exist!")
        with open(split_file, "r") as f:
            splits = json.load(f)
        train_rgb_file_paths = sorted([os.path.join(args.data_path, "undistorted_images_2", file_name) for file_name in splits["train"]])
        test_rgb_file_paths = sorted([os.path.join(args.data_path, "undistorted_images_2", file_name) for file_name in splits["test"]])
        train_camera_poses, test_camera_poses, intrinsics = read_scannetpp_cameras(args.data_path)
    else:
        raise TypeError(f"Unsupported dataset type: {args.data_type}!")

    # Load a keyframe list to only select keyframes from ground truth data for further refinement of the 3DGS model (Recommended to reduce optimization time)
    if os.path.exists(args.sparse_kf_list):
        with open(args.sparse_kf_list, "r") as f:
            sparse_kf_index = [int(line.strip()) - 1 for line in f]
        shutil.copy(args.sparse_kf_list, args.output_dir)
        train_rgb_file_paths = [train_rgb_file_paths[idx] for idx in sparse_kf_index]
        train_camera_poses = [train_camera_poses[idx] for idx in sparse_kf_index]

    if args.eval:
        novel_views = test_camera_poses
    else:
        if not os.path.exists(args.novel_views):
            raise FileNotFoundError(f"{args.novel_views} doesn't exist!")
        with open(args.novel_views, "r") as f:
            novel_views = json.load(f)
        shutil.copy(args.novel_views, args.output_dir)
    
    # Confirm which 3DGS model to use (following the file structure generated by the Inria 3DGS code)
    if args.iteration == -1:
        loaded_iter = searchForMaxIteration(os.path.join(model_params.model_path, "point_cloud"))
    else:
        loaded_iter = args.iteration
    
    # Load the 3DGS model
    gaussians = GaussianModel(model_params.sh_degree)
    gaussians.load_ply(os.path.join(model_params.model_path,
                                    "point_cloud",
                                    "iteration_" + str(loaded_iter),
                                    "point_cloud.ply"))
    gaussians.training_setup(optim_params)

    fov_x = focal2fov(intrinsics["fx"], intrinsics["width"])
    fov_y = focal2fov(intrinsics["fy"], intrinsics["height"])
    bg_color = [1, 1, 1] if model_params.white_background else [0, 0, 0]
    background = torch.tensor(bg_color, dtype=torch.float32, device=device)

    to_tensor = transforms.ToTensor()

    # Optmization over fixed novel view images obtained from GSFixer
    print("Start optmization over fixed images from GSFixer...")
    for i in tqdm(range(len(novel_views))):
        if args.eval:
            T_WC = novel_views[i]
            T_CW = np.linalg.inv(T_WC)
        else:
            T_CW = np.array(novel_views[i]["extrinsic"])
            T_WC = np.linalg.inv(T_CW)

        fixed_image = Image.open(fixed_rgb_file_paths[i])
        gt_image = to_tensor(fixed_image)
        gt_image = gt_image.cuda()

        gs_cam = Camera(R=T_CW[:3, :3], T=T_CW[:3, 3], FoVx=fov_x, FoVy=fov_y, width=intrinsics["width"], height=intrinsics["height"])
        for iter in range(args.iters):
            render_pkg = render(gs_cam, gaussians, pipeline_params, background)
            rendered_gs, viewspace_point_tensor, visibility_filter = render_pkg["render"], render_pkg["viewspace_points"], render_pkg["visibility_filter"]
            loss = 0.8 * l1_loss(rendered_gs, gt_image) + 0.2 * (1 - ssim(rendered_gs, gt_image))
            loss.backward()
            
            gaussians.add_densification_stats(viewspace_point_tensor, visibility_filter)
            if iter % 5 == 0:
                # print(gaussians.get_xyz.shape[0])
                gaussians.densify(optim_params.densify_grad_threshold)
                # print(gaussians.get_xyz.shape[0])
            if iter == (args.iters -1):
                gaussians.prune(optim_params.prune_opacity_threshold)

            gaussians.optimizer.step()
            gaussians.optimizer.zero_grad(set_to_none = True)

        train_rgb_file_paths.append(fixed_rgb_file_paths[i])
        train_camera_poses.append(T_WC)
    
    # Optimization over the extended training dataset
    print("Start optimization over the extended training dataset...")
    for iter in tqdm(range(args.kf_iters)):
        indices = list(range(len(train_rgb_file_paths)))
        random.shuffle(indices)
        for kf_idx in indices:
            T_kf = train_camera_poses[kf_idx]
            T_kf_inv = np.linalg.inv(T_kf)
            gs_cam_kf = Camera(R=T_kf_inv[:3, :3], T=T_kf_inv[:3, 3], FoVx=fov_x, FoVy=fov_y, width=intrinsics["width"], height=intrinsics["height"])
            
            kf_img = Image.open(train_rgb_file_paths[kf_idx])
            gt_image = to_tensor(kf_img)
            gt_image = gt_image.cuda()

            rendered_gs = render(gs_cam_kf, gaussians, pipeline_params, background)["render"]
            loss = 0.8 * l1_loss(rendered_gs, gt_image) + 0.2 * (1 - ssim(rendered_gs, gt_image))
            loss.backward()
            gaussians.optimizer.step()
            gaussians.optimizer.zero_grad(set_to_none = True)

    # Save the refined 3DGS model
    gaussians.save_ply(os.path.join(args.output_dir, "point_cloud.ply"))

    # Render novel views from refined 3DGS model
    print("Start rendering novel views from the refined 3DGS model...")
    for i in tqdm(range(len(novel_views))):
        if args.eval:
            T_WC = novel_views[i]
            T_CW = np.linalg.inv(T_WC)
        else:
            T_CW = np.array(novel_views[i]["extrinsic"])

        gs_cam = Camera(R=T_CW[:3, :3], T=T_CW[:3, 3], FoVx=fov_x, FoVy=fov_y, width=intrinsics["width"], height=intrinsics["height"])
        with torch.no_grad():
            rendered_gs = render(gs_cam, gaussians, pipeline_params, background)["render"]
            rendered_gs_image = rendered_gs.detach().cpu().numpy().transpose(1, 2, 0) * 255
            rendered_gs_image = rendered_gs_image.astype(np.uint8)
            rendered_gs_pil = Image.fromarray(rendered_gs_image)
            save_path = os.path.join(args.output_dir, "refined_novel_views", f"{i:05d}.png")
            rendered_gs_pil.save(save_path, format="PNG")

    # Calculate evaluation metrics for refined novel view images
    if args.eval:
        print("Evaluation metrics for refined novel view images:")
        eval_image(
            test_rgb_file_paths,
            os.path.join(args.output_dir, "refined_novel_views"),
            os.path.join(args.output_dir, "refined_gs_metrics.json")
        )


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="GSFix3D: Diffusion-Guided Novel View Repair")

    model = ModelParams(parser, sentinel=True)
    optim = OptimizationParams(parser)
    pipeline = PipelineParams(parser)
    
    parser.add_argument("--iteration", type=int, default=-1, help="A 3DGS model from this specific iteration will be loaded following Inria 3DGS file structure")
    parser.add_argument("--data_type", type=str, default="replica", choices=["replica", "scannetpp"], help="Supported data type")
    parser.add_argument("--data_path", type=str, help="Path to ground truth data")
    parser.add_argument("--sparse_kf_list", type=str, default="", help="A keyframe list to only select keyframes from ground truth data")
    parser.add_argument("--fixed_image_path", type=str, help="Path to fixed novel view images obtained from GSFixer")
    parser.add_argument("--novel_views", type=str, help="JSON file path to novel view camera poses")
    parser.add_argument("--eval", action="store_true", help="Enable evaluation")
    parser.add_argument("--iters", type=int, default=20, help="The number of optimization iterations for each fixed image")
    parser.add_argument("--kf_iters", type=int, default=50, help="The number of optimization iterations for the extended training dataset")
    parser.add_argument("--output_dir", type=str, default="output_gsfix3d", help="Folder path to store results")
    args = get_combined_args(parser)

    main(args, model.extract(args), optim.extract(args), pipeline.extract(args))
